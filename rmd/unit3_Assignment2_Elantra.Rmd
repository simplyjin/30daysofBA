---
title: "Elantra Sales"
author: "Jin Chen"
date: "10/8/2020"
output: html_document
---
```{r}
library(tidyverse)
```


# Problem 1 - Loading the Data

Load the data set. Split the data set into training and testing sets as follows: place all observations for 2012 and earlier in the training set, and all observations for 2013 and 2014 into the testing set.

How many observations are in the training set? 36

```{r}
elantra <- read_csv("../data/elantra.csv")
str(elantra)

elantra_train <- elantra %>% 
  filter(Year <= 2012)

elantra_test <- elantra %>% 
  filter(Year > 2012)

```

# Problem 2.1 - A Linear Regression Model

Build a linear regression model to predict monthly Elantra sales using Unemployment, CPI_all, CPI_energy and Queries as the independent variables. Use all of the training set data to do this.

What is the model R-squared? Note: In this problem, we will always be asking for the "Multiple R-Squared" of the model. 0.4281568

```{r}
library(tidymodels)

lm.model = linear_reg() %>%
  set_engine(engine = "lm") %>%
  set_mode(mode = "regression")

lm.fit <- lm.model %>% 
  fit(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries, data = elantra_train)
lm.fit
glance(lm.fit)

```


# Problem 2.2 - Significant Variables
How many variables are significant, or have levels that are significant? Use 0.10 as your p-value cutoff. 0

```{r}
lm.fit.stats <- lm.fit %>% 
  tidy(interval = TRUE)
lm.fit.stats

```

# Problem 2.3 - Coefficients

What is the coefficient of the Unemployment variable? -3179.89957	

# Problem 2.4 - Interpreting the Coefficient

What is the interpretation of this coefficient? For an increase of 1 in Unemployment, the prediction of Elantra sales decreases by approximately 3000. 

# Problem 3.1 - Modeling Seasonality

Our model R-Squared is relatively low, so we would now like to improve our model. In modeling demand and sales, it is often useful to model seasonality. Seasonality refers to the fact that demand is often cyclical/periodic in time. For example, in countries with different seasons, demand for warm outerwear (like jackets and coats) is higher in fall/autumn and winter (due to the colder weather) than in spring and summer. (In contrast, demand for swimsuits and sunscreen is higher in the summer than in the other seasons.) Another example is the "back to school" period in North America: demand for stationary (pencils, notebooks and so on) in late July and all of August is higher than the rest of the year due to the start of the school year in September.

In our problem, since our data includes the month of the year in which the units were sold, it is feasible for us to incorporate monthly seasonality. From a modeling point of view, it may be reasonable that the month plays an effect in how many Elantra units are sold.

To incorporate the seasonal effect due to the month, build a new linear regression model that predicts monthly Elantra sales using Month as well as Unemployment, CPI_all, CPI_energy and Queries. Do not modify the training and testing data frames before building the model.

What is the model R-Squared? 0.4344443

```{r}
lm.fit2 <- lm.model %>% 
  fit(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries + Month, data = elantra_train)
lm.fit2
glance(lm.fit2)

lm.fit.stats2 <- lm.fit2 %>% 
  tidy(interval = TRUE)
lm.fit.stats2


```

# Problem 3.2 - Effect of Adding a New Variable

Which of the following best describes the effect of adding Month? The model is not better because the adjusted R-squared has gone down and none of the variables (including the new one) are very significant.

Explanation:  The first option is incorrect because (ordinary) R-Squared always increases (or at least stays the same) when you add new variables. This does not make the model better, and in fact, may hurt the ability of the model to generalize to new, unseen data (overfitting).

The second option is correct: the adjusted R-Squared is the R-Squared but adjusted to take into account the number of variables. If the adjusted R-Squared is lower, then this indicates that our model is not better and in fact may be worse. Furthermore, if none of the variables have become significant, then this also indicates that the model is not better.
```{r}
glance(lm.fit)
glance(lm.fit2)
```


# Problem 3.3 - Understanding the Model

Let us try to understand our model.

In the new model, given two monthly periods that are otherwise identical in Unemployment, CPI_all, CPI_energy and Queries, what is the absolute difference in predicted Elantra sales given that one period is in January and one is in March?  221.3705
In the new model, given two monthly periods that are otherwise identical in Unemployment, CPI_all, CPI_energy and Queries, what is the absolute difference in predicted Elantra sales given that one period is in January and one is in May? 442.7411
 
```{r}
elantra
lm.fit.stats2

2*110.68527
4*110.68527

```

# Problem 3.4 - Numeric vs. Factors

You may be experiencing an uneasy feeling that there is something not quite right in how we have modeled the effect of the calendar month on the monthly sales of Elantras. If so, you are right. In particular, we added Month as a variable, but Month is an ordinary numeric variable. In fact, we must convert Month to a factor variable before adding it to the model.

What is the best explanation for why we must do this? By modeling Month as a factor variable, the effect of each calendar month is not restricted to be linear in the numerical coding of the month.


# Problem 4.1 - A New Model

Re-run the regression with the Month variable modeled as a factor variable. (Create a new variable that models the Month as a factor (using the as.factor function) instead of overwriting the current Month variable. We'll still use the numeric version of Month later in the problem.)

What is the model R-Squared? 0.8192642

```{r}
elantra_train <- elantra_train %>% 
  mutate(MonthFactor = as.factor(as.numeric(Month)))

lm.fit3 <- lm.model %>% 
  fit(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries + MonthFactor, data = elantra_train)
lm.fit3
glance(lm.fit3)

lm.fit.stats3 <- lm.fit3 %>% 
  tidy(interval = TRUE)
lm.fit.stats3

```

# Problem 4.2 - Significant Variables

Which variables are significant, or have levels that are significant? Use 0.10 as your p-value cutoff.  Month(the factor version), CPI_all, CPI_energy, Unemployment

# Problem 5.1 - Multicolinearity

Another peculiar observation about the regression is that the sign of the Queries variable has changed. In particular, when we naively modeled Month as a numeric variable, Queries had a positive coefficient. Now, Queries has a negative coefficient. Furthermore, CPI_energy has a positive coefficient -- as the overall price of energy increases, we expect Elantra sales to increase, which seems counter-intuitive (if the price of energy increases, we'd expect consumers to have less funds to purchase automobiles, leading to lower Elantra sales).

As we have seen before, changes in coefficient signs and signs that are counter to our intuition may be due to a multicolinearity problem. To check, compute the correlations of the variables in the training set.

Which of the following variables is CPI_energy highly correlated with? Select all that apply. (Include only variables where the absolute value of the correlation exceeds 0.6. For the purpose of this question, treat Month as a numeric variable, not a factor variable.) Unemployment, Queries, CPI_all

```{r}
library(corrr)

elantra_train %>% 
  select(-MonthFactor) %>% 
  correlate() %>% 
  focus(CPI_energy)

```

# Problem 5.2 - Correlations

Which of the following variables is Queries highly correlated with? Again, compute the correlations on the training set. Select all that apply. (Include only variables where the absolute value of the correlation exceeds 0.6. For the purpose of this question, treat Month as a numeric variable, not a factor variable.) Unemployment, CPI_energy, CPI_all

```{r}
elantra_train %>% 
  select(-MonthFactor) %>% 
  correlate() %>% 
  focus(Queries)

```

# Problem 6.1 - A Reduced Model

Let us now simplify our model (the model using the factor version of the Month variable). We will do this by iteratively removing variables, one at a time. Remove the variable with the highest p-value (i.e., the least statistically significant variable) from the model. Repeat this until there are no variables that are insignificant or variables for which all of the factor levels are insignificant. Use a threshold of 0.10 to determine whether a variable is significant.

Which variables, and in what order, are removed by this process? Queries 

```{r}
lm.fit3 <- lm.model %>% 
  fit(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries + MonthFactor, data = elantra_train)
lm.fit3
glance(lm.fit3)

lm.fit.stats3 <- lm.fit3 %>% 
  tidy(interval = TRUE)
lm.fit.stats3

lm.fit4 <- lm.model %>% 
  fit(ElantraSales ~ Unemployment + CPI_all + CPI_energy + MonthFactor, data = elantra_train)

lm.fit.stats4 <- lm.fit4 %>% 
  tidy(interval = TRUE)
lm.fit.stats4


```

# Problem 6.2 - Test Set Predictions

Using the model from Problem 6.1, make predictions on the test set. What is the sum of squared errors of the model on the test set?

```{r}
elantra_test <- elantra_test %>% 
  mutate(MonthFactor = as.factor(as.numeric(Month)))

lm.predict <- lm.fit4 %>% 
  predict(elantra_test) %>% 
  bind_cols(elantra_test)
lm.predict

rmse(lm.predict, truth = ElantraSales, estimate = .pred)
nrow(elantra_test)

# SSE <- sum((predTest - pisaTest$readingScore)^2)
# SST <- sum((mean(pisaTrain$readingScore) - pisaTest$readingScore)^2)
# RMSE <- sqrt(SSE/nrow(pisaTest))

SSE <- sum((lm.predict$.pred - elantra_test$ElantraSales)^2)
SSE



```

# Problem 6.3 - Comparing to a Baseline

What would the baseline method predict for all observations in the test set? Remember that the baseline method we use predicts the average outcome of all observations in the training set. 14462.25

```{r}
elantra_train %>% 
  summarize(mean = mean(ElantraSales))

```

# Problem 6.4 - Test Set R-Squared

What is the test set R-Squared? 0.7280232

```{r}
# SST <- sum((mean(pisaTrain$readingScore) - pisaTest$readingScore)^2)

SST <- sum((mean(elantra_train$ElantraSales) - elantra_test$ElantraSales)^2)
R2 <- 1 - SSE/SST
R2

```



# Problem 6.5 - Absolute Errors

What is the largest absolute error that we make in our test set predictions? 7491.4877

```{r}
# lm.predict2 <- augment(lm.fit4$fit, data = elantra_train) %>% 
#     rowid_to_column()
# select(lm.predict2, rowid, Month, Year, ElantraSales, .fitted:.std.resid)

lm.predict2 <- augment(lm.fit4$fit, newdata = elantra_test)

lm.predict2 %>% 
  arrange(desc(.resid))


```

# Problem 6.6 - Month of Largest Error

In which period (Month,Year pair) do we make the largest absolute error in our prediction? 03/2013 